{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ§  Brain Tumor Classification using VGG16\n",
        "\n",
        "## ğŸ“Œ Project Overview\n",
        "\n",
        "In this notebook, we will develop a deep learning model to automatically detect and classify brain tumors from MRI images. The goal of this project is to assist medical professionals in identifying four specific categories of brain conditions:\n",
        "\n",
        "- **Glioma Tumor**\n",
        "- **Meningioma Tumor**\n",
        "- **Pituitary Tumor**\n",
        "- **No Tumor**\n",
        "\n",
        "Accurate and early detection of brain tumors is crucial for effective treatment planning and improved patient outcomes. Manual diagnosis from MRI scans can be time-consuming and subjective, so our goal is to build a model that can support this process with high accuracy and consistency.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§° What We'll Do\n",
        "\n",
        "- Load and preprocess a labeled dataset of brain MRI images.\n",
        "- Visualize example images from each tumor category.\n",
        "- Use **transfer learning** with the **VGG16** architecture, a pre-trained Convolutional Neural Network originally trained on ImageNet.\n",
        "- Fine-tune the model for multi-class classification specific to our problem.\n",
        "- Evaluate the modelâ€™s performance using accuracy, confusion matrix, and classification report.\n",
        "- Test the model on new images to validate its predictions.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  Why VGG16?\n",
        "\n",
        "VGG16 is a widely used CNN architecture known for its simplicity and strong performance in image classification tasks. By leveraging a pre-trained version of VGG16, we can reduce training time and achieve better performance, especially when working with a limited dataset.\n",
        "\n",
        "---\n",
        "\n",
        "Let's get started with loading the data and exploring the dataset!"
      ],
      "metadata": {
        "id": "ANd2-5cXm4WK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data and import libraries"
      ],
      "metadata": {
        "id": "wlcnzKvDgUj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQA-lROLm1Q8",
        "outputId": "6d234295-a8bf-4525-9f16-b4cc79a0170f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/brain-tumor-mri-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import  Dense,Dropout,Conv2D,MaxPooling2D,Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "os.listdir(path)\n",
        "training_data=path+'/Training'\n",
        "testing_data=path+'/Testing'\n",
        "os.listdir(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBkxFhfCm9Eo",
        "outputId": "7a43bb9d-ecc2-4d0d-aa85-dd4a094eb810"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pituitary', 'notumor', 'meningioma', 'glioma']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=[]\n",
        "y=[]\n",
        "def load_data(path, x, y):\n",
        "  x.clear()\n",
        "  y.clear()\n",
        "  for i in os.listdir(path):\n",
        "    for j in os.listdir(path+'/'+i):\n",
        "      img=cv2.imread(path+'/'+i+'/'+j)\n",
        "      img=cv2.resize(img,(224,224))\n",
        "      x.append(img)\n",
        "      y.append(i)\n",
        "\n",
        "\n",
        "load_data(training_data, x, y)"
      ],
      "metadata": {
        "id": "UZ0Dt4KNnEro"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x),len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhPe4l4Ho-ON",
        "outputId": "e9ce1c20-f09a-45fe-dac2-85cc1bd3c3b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5712, 5712)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=np.array(y)\n",
        "y=[0 if i=='glioma' else 1 if i=='meningioma' else 2 if i=='pituitary' else 3 for i in y]\n",
        "y = np.array(y)\n"
      ],
      "metadata": {
        "id": "9CNRPe_7o-hm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## split to train and valid"
      ],
      "metadata": {
        "id": "2VwFD_qRg9Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_vald,y_train,y_vald=train_test_split(x,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "iG3SFqzMxyh0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load VGG16"
      ],
      "metadata": {
        "id": "Ob_2dyOMgffU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VGG16_model=VGG16(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
        "for layer in VGG16_model.layers:\n",
        "  layer.trainable=False"
      ],
      "metadata": {
        "id": "0gP_40_Np448"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(VGG16_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4,activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "EarlyStopping=EarlyStopping(monitor='val_loss',patience=5,verbose=1,mode='min')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "oP6NVHp6qvsa",
        "outputId": "7c3fd544-a295-46c6-a0ac-c707e715b3d4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚    \u001b[38;5;34m14,714,688\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              â”‚       \u001b[38;5;34m100,356\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,356</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,815,044\u001b[0m (56.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,815,044</span> (56.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,356\u001b[0m (392.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,356</span> (392.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['Precision'])"
      ],
      "metadata": {
        "id": "P_Idn-3EtCV4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation for Generalization"
      ],
      "metadata": {
        "id": "2USNghxfgsB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=25,\n",
        "    brightness_range=[0.5, 1.5]\n",
        ")\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Convert x_train to numpy array and one-hot encode y_train\n",
        "x_train_np = np.array(x_train)\n",
        "y_train_encoded = to_categorical(y_train, num_classes=4)\n",
        "y_test_encoded = to_categorical(y_vald, num_classes=4)\n",
        "\n",
        "\n",
        "generator = datagen.flow(x_train_np, y_train_encoded, batch_size=batch_size)\n",
        "\n",
        "model.fit(generator, epochs=10, steps_per_epoch=len(x_train)//batch_size, validation_data=(np.array(x_vald), y_test_encoded),callbacks=[EarlyStopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRA8Qjm18q8n",
        "outputId": "06c47ede-4a94-49f4-946c-565dd41456be"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 649ms/step - Precision: 0.7517 - loss: 4.7241 - val_Precision: 0.8591 - val_loss: 3.6221\n",
            "Epoch 2/10\n",
            "\u001b[1m  1/142\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m24s\u001b[0m 173ms/step - Precision: 0.9062 - loss: 2.3101"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 73ms/step - Precision: 0.9062 - loss: 2.3101 - val_Precision: 0.8346 - val_loss: 4.5142\n",
            "Epoch 3/10\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 531ms/step - Precision: 0.9057 - loss: 1.9509 - val_Precision: 0.9046 - val_loss: 2.4077\n",
            "Epoch 4/10\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 73ms/step - Precision: 0.8438 - loss: 5.6922 - val_Precision: 0.9204 - val_loss: 2.1144\n",
            "Epoch 5/10\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 528ms/step - Precision: 0.9446 - loss: 1.0453 - val_Precision: 0.9134 - val_loss: 2.6267\n",
            "Epoch 6/10\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 73ms/step - Precision: 0.9375 - loss: 0.9882 - val_Precision: 0.9046 - val_loss: 2.7373\n",
            "Epoch 7/10\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 507ms/step - Precision: 0.9574 - loss: 0.8114 - val_Precision: 0.9230 - val_loss: 2.3661\n",
            "Epoch 8/10\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 73ms/step - Precision: 0.8750 - loss: 2.0637 - val_Precision: 0.9379 - val_loss: 2.1379\n",
            "Epoch 9/10\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 513ms/step - Precision: 0.9512 - loss: 1.1014 - val_Precision: 0.9204 - val_loss: 2.5769\n",
            "Epoch 9: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7efa6d6eb890>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation"
      ],
      "metadata": {
        "id": "dTHDgUUwg2pU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load test data"
      ],
      "metadata": {
        "id": "gH6ZzTeYhBYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_text=[]\n",
        "y_test=[]\n",
        "\n",
        "def load_data(path):\n",
        "  for i in os.listdir(path):\n",
        "    for j in os.listdir(path+'/'+i):\n",
        "      img=cv2.imread(path+'/'+i+'/'+j)\n",
        "      img=cv2.resize(img,(224,224))\n",
        "      x_text.append(img)\n",
        "      y_test.append(i)\n",
        "\n",
        "\n",
        "\n",
        "load_data(testing_data)\n",
        "y_test=np.array(y_test)\n",
        "print(len(x_text),len(y_test))\n",
        "y_test=[0 if i=='glioma' else 1 if i=='meningioma' else 2 if i=='pituitary' else 3 for i in y_test]\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPzgKcfFWXDy",
        "outputId": "a3bd9f8a-867a-4bda-facd-a2545ecf3bb2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1311 1311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(np.array(x_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6qYltdWWztm",
        "outputId": "0379d89e-9b7d-4ad1-935f-0ea30fcd4d55"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 418ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "y_pred=np.argmax(y_pred,axis=1)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yztirlz4W1uk",
        "outputId": "a16245da-91f8-4ff7-abaf-98a09f95f3a2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91       300\n",
            "           1       0.96      0.78      0.86       306\n",
            "           2       0.93      0.99      0.96       300\n",
            "           3       0.99      0.99      0.99       405\n",
            "\n",
            "    accuracy                           0.93      1311\n",
            "   macro avg       0.93      0.93      0.93      1311\n",
            "weighted avg       0.94      0.93      0.93      1311\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## save model"
      ],
      "metadata": {
        "id": "9K2nMqTHg5TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.keras')"
      ],
      "metadata": {
        "id": "rDh__F8wbMOU"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}